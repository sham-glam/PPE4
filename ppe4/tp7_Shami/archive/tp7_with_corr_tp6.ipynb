{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4c87f6f-2996-401e-8543-b682d17c7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import utils_TP4 as utils\n",
    "import solution_TP4 as solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41f198-bf2d-4fce-8911-12fd49d6f0ee",
   "metadata": {},
   "source": [
    "# Utilisation de Dataset (en gardant les anciens modèle et TextVectorizationLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d35a66-f44e-4517-b0b8-a3f680c5eb32",
   "metadata": {},
   "source": [
    "### Récupération et affichage d'une instance dans le corpus pour vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52859290-c295-4b4c-9222-150641025670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3498 files belonging to 7 classes.\n",
      "Using 2449 files for training.\n",
      "Using 1049 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_valid = keras.utils.text_dataset_from_directory(\n",
    "    \"Corpus\",\n",
    "    seed=42,\n",
    "    validation_split=0.3,\n",
    "    subset='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f7fa9-e0ac-405e-b6ed-d2bc693f838e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3931b5b7-dc5c-4c9a-b3b2-6d1bd8cba143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b\"   Les Combattants est un film fran\\xc3\\xa7ais r\\xc3\\xa9alis\\xc3\\xa9 par Thomas Cailley , sorti\\n   le 20 ao\\xc3\\xbbt 2014 .\\n   R\\xc3\\xa9alisation Sc\\xc3\\xa9nario Acteurs principaux Pays de production Genre Dur\\xc3\\xa9e\\n   Sortie\\n\\n   Les Combattants est un film fran\\xc3\\xa7ais r\\xc3\\xa9alis\\xc3\\xa9 par Thomas Cailley , sorti\\n   le 20 ao\\xc3\\xbbt 2014 .\\n   R\\xc3\\xa9alisation Sc\\xc3\\xa9nario Acteurs principaux Pays de production Genre Dur\\xc3\\xa9e\\n   Sortie\\n\\n   Les Combattants d'Afrique est une exposition temporaire qui s'est\\n   d\\xc3\\xa9roul\\xc3\\xa9e du 15 juin 2010 au 31 octobre 2010 au Centre national\\n   Jean-Moulin de Bordeaux . Elle s'inscrit dans le cadre de la\\n   comm\\xc3\\xa9moration du 70 ^e anniversaire de l' Appel du 18 Juin 1940 par le\\n   g\\xc3\\xa9n\\xc3\\xa9ral de Gaulle , et du Cinquantenaire des Ind\\xc3\\xa9pendances et des\\n   actions engag\\xc3\\xa9es par la municipalit\\xc3\\xa9 de Bordeaux en direction des\\n   anciens combattants d'Afrique. L'exposition est pr\\xc3\\xa9sent\\xc3\\xa9e comme un\\n   hommage de la ville de Bordeaux, du Centre Jean-Moulin et du Minist\\xc3\\xa8re\\n   de la D\\xc3\\xa9fense aux anciens combattants d'Afrique.\\n   Type Pays Localisation Commissaire Date d'ouverture Date de cl\\xc3\\xb4ture\\n   Organisateur(s)\\n\\n   Les Combattants de Serkos est un roman de science-fiction d' Andr\\xc3\\xa9\\n   Caroff , paru en 1978 .\\n   Auteur Pays Genre Version originale Langue Date de parution Version\\n   fran\\xc3\\xa7aise \\xc3\\x89diteur Collection Date de parution\\n\\n\">,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=6>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_elem = ds_train.unbatch().take(1).get_single_element()\n",
    "un_elem   # equivalent of tst_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491a3d0-de75-4290-8ca1-8ad51cef618d",
   "metadata": {},
   "source": [
    "### Vectorisation du corpus\n",
    "\n",
    "On `adapt()` le text_vectorizer en laissant de côté les `y` avec la fonction lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b8d196-3147-4285-89ac-cd25a610311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = solution.get_text_vectorizer_from_config(solution.ExpeConfig(\"whitespace\",None,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305a0e93-ad5e-4a1f-aa11-e414cfc0e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.adapt(ds_train.map(lambda x,y: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f8c13-4615-4bfc-9494-b6e2d870ba4e",
   "metadata": {},
   "source": [
    "#### Vérification des structures de données obtenues (on vérifie les types et les shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40704ba0-ca58-4385-abf7-23b7679317f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 1000), dtype=float32, numpy=\n",
       " array([[143.,  20.,  13., ...,   0.,   0.,   0.],\n",
       "        [  7.,   2.,   0., ...,   0.,   0.,   0.],\n",
       "        [111.,  12.,   8., ...,   0.,   0.,   0.],\n",
       "        ...,\n",
       "        [ 48.,  10.,   2., ...,   0.,   0.,   0.],\n",
       "        [ 21.,   6.,   3., ...,   0.,   0.,   0.],\n",
       "        [132.,  12.,   0., ...,   0.,   0.,   0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([4, 6, 4, 1, 5, 0, 0, 2, 1, 6, 1, 6, 6, 6, 6, 1, 0, 6, 2, 5, 1, 3,\n",
       "        6, 2, 4, 0, 2, 5, 5, 5, 6, 6], dtype=int32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.map(lambda x,y: (tv(x),y)).take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96588e-67d6-4d07-9b2f-685cc2211eba",
   "metadata": {},
   "source": [
    "### Création et entraînement du modèle\n",
    "(et fonction de preprocessing qui peut remplacer la lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed752a7-9b84-432d-8ef3-6eb1f96ba6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.PerceptronModelSparseCategorical(tv, list(range(7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eead739d-47ea-40c0-a56a-2b29dd462e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(x,y):\n",
    "    return tv(x),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91705c9-9c66-4729-be60-4f43313c6917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "77/77 [==============================] - 1s 6ms/step - loss: 1.1860 - accuracy: 0.6840 - val_loss: 0.6682 - val_accuracy: 0.8532\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8767 - val_loss: 0.5420 - val_accuracy: 0.8694\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.9061 - val_loss: 0.4951 - val_accuracy: 0.8808\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.9261 - val_loss: 0.4804 - val_accuracy: 0.8847\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.9334 - val_loss: 0.4729 - val_accuracy: 0.8894\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9420 - val_loss: 0.4712 - val_accuracy: 0.8827\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9530 - val_loss: 0.4808 - val_accuracy: 0.8808\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9592 - val_loss: 0.4733 - val_accuracy: 0.8818\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9690 - val_loss: 0.4756 - val_accuracy: 0.8837\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9747 - val_loss: 0.4855 - val_accuracy: 0.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x747357e2c0d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train.map(preproc), validation_data=ds_valid.map(preproc), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddf0ab8-2e47-45fc-acb1-c9f3bc116746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TextVectorization.vocabulary_size of <keras.src.layers.preprocessing.text_vectorization.TextVectorization object at 0x7473db8f5890>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c85d284-5136-4297-93fb-ef2d137bc2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tokens_count (InputLayer)   [(None, 1000)]            0         \n",
      "                                                                 \n",
      " normalizer (Normalization)  (None, 1000)              2001      \n",
      "                                                                 \n",
      " hidden (Dense)              (None, 14)                14014     \n",
      "                                                                 \n",
      " sortie (Dense)              (None, 7)                 105       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16120 (62.97 KB)\n",
      "Trainable params: 14119 (55.15 KB)\n",
      "Non-trainable params: 2001 (7.82 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5169c2b-bef2-4b00-a10d-7b03b51444c6",
   "metadata": {},
   "source": [
    "# Utilisation de plongements (Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c49fed-05a6-4eaf-b041-d5b4de8fa430",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_int = text_vectorizer = keras.layers.TextVectorization(\n",
    "    max_tokens=3000, # taille du vocabulaire conservé\n",
    "    output_sequence_length=100, # taille des séquences (tronquées ou en ajoutant du padding)\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\") # changement : \"int\" au lieu de \"count\" pour un encodage un token -> un entier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac09df1c-b122-4d22-97dd-0a4faeffe885",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_int.adapt(ds_train.map(lambda x,y:x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9b41bf-9324-41b3-817f-5179759d1fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([   5, 1953,   65,    2,  122,    6,    8,   65,    1,   72,  120,\n",
       "          5,   78,    6,    9,  219,  131,    4,    1,   92, 1905,    2,\n",
       "          1,  906,    3,  228,    1,   39,    3, 1899,    2,    1, 2077,\n",
       "          3,  237,  335,    5,   21,    2, 1953,   65,    2,  122,   12,\n",
       "        444,   11,   65,   63,    1,    9,    3,    1,    2,    3, 1899,\n",
       "          2,    1,    7,    9,    1,    2,    1,   85,  877,   48,  202,\n",
       "        750,  503, 1930,   78,   16,   62,  107,   36,   40,    1, 2950,\n",
       "         12,    1,   11, 1953,   65,    2,  122,   63,   12, 1324,    1,\n",
       "          2,  511,    1,   10,    5, 1953,   65,    2,  122,   73,  106,\n",
       "         85])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_x = ds_train.unbatch().map(lambda x,y:x).map(tv_int).take(1).get_single_element()\n",
    "one_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d871c-c121-4207-bbfe-05a40cb14a40",
   "metadata": {},
   "source": [
    "### On peut vérifier qu'on est capable de réencoder un document pour voir si tout se passe comme prévu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fac71808-3f6d-4ceb-b705-5fb044329a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tv_int.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78102d24-4f91-47f8-86b3-183a4390e530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le',\n",
       " 'yacht',\n",
       " 'club',\n",
       " 'de',\n",
       " 'france',\n",
       " 'est',\n",
       " 'un',\n",
       " 'club',\n",
       " '[UNK]',\n",
       " 'français',\n",
       " 'dont',\n",
       " 'le',\n",
       " 'siège',\n",
       " 'est',\n",
       " 'à',\n",
       " 'paris',\n",
       " 'créée',\n",
       " 'en',\n",
       " '[UNK]',\n",
       " 'sous',\n",
       " 'légide',\n",
       " 'de',\n",
       " '[UNK]',\n",
       " 'iii',\n",
       " 'la',\n",
       " 'société',\n",
       " '[UNK]',\n",
       " 'pour',\n",
       " 'la',\n",
       " 'navigation',\n",
       " 'de',\n",
       " '[UNK]',\n",
       " 'prend',\n",
       " 'la',\n",
       " 'même',\n",
       " 'année',\n",
       " 'le',\n",
       " 'titre',\n",
       " 'de',\n",
       " 'yacht',\n",
       " 'club',\n",
       " 'de',\n",
       " 'france',\n",
       " 'les',\n",
       " 'activités',\n",
       " 'du',\n",
       " 'club',\n",
       " 'sont',\n",
       " '[UNK]',\n",
       " 'à',\n",
       " 'la',\n",
       " '[UNK]',\n",
       " 'de',\n",
       " 'la',\n",
       " 'navigation',\n",
       " 'de',\n",
       " '[UNK]',\n",
       " 'et',\n",
       " 'à',\n",
       " '[UNK]',\n",
       " 'de',\n",
       " '[UNK]',\n",
       " 'fondation',\n",
       " 'sigle',\n",
       " 'type',\n",
       " 'forme',\n",
       " 'juridique',\n",
       " 'domaine',\n",
       " 'dactivité',\n",
       " 'siège',\n",
       " 'pays',\n",
       " 'coordonnées',\n",
       " 'président',\n",
       " 'site',\n",
       " 'web',\n",
       " '[UNK]',\n",
       " 'siren',\n",
       " 'les',\n",
       " '[UNK]',\n",
       " 'du',\n",
       " 'yacht',\n",
       " 'club',\n",
       " 'de',\n",
       " 'france',\n",
       " 'sont',\n",
       " 'les',\n",
       " 'différentes',\n",
       " '[UNK]',\n",
       " 'de',\n",
       " 'course',\n",
       " '[UNK]',\n",
       " 'par',\n",
       " 'le',\n",
       " 'yacht',\n",
       " 'club',\n",
       " 'de',\n",
       " 'france',\n",
       " 'depuis',\n",
       " 'sa',\n",
       " 'fondation']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[i] for i in one_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7214b3a-780d-4219-8bfe-7e2f98a07584",
   "metadata": {},
   "source": [
    "# Une couche d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d025b6f-79e1-4138-9073-43906ac79057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
       "array([[ 0.02338589, -0.02350946,  0.04454089],\n",
       "       [-0.03283953,  0.03530599, -0.03119474],\n",
       "       [ 0.03748092, -0.03771096,  0.04293822],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.0345609 ,  0.02477014,  0.02694254],\n",
       "       [-0.03433607, -0.00805996,  0.02791429],\n",
       "       [ 0.02642215,  0.02735001,  0.04771307],\n",
       "       [ 0.03748092, -0.03771096,  0.04293822],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [-0.04193065, -0.04257564,  0.01240958],\n",
       "       [-0.02615769, -0.02718338, -0.02671988],\n",
       "       [ 0.02338589, -0.02350946,  0.04454089],\n",
       "       [ 0.03798262,  0.01415141, -0.03752277],\n",
       "       [-0.03433607, -0.00805996,  0.02791429],\n",
       "       [-0.04183261, -0.03248701,  0.02310926],\n",
       "       [-0.01814044,  0.0447191 , -0.0272627 ],\n",
       "       [ 0.04439044, -0.00499889, -0.00600236],\n",
       "       [ 0.02035601, -0.04105066,  0.00040861],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.01475232, -0.04128289, -0.00464964],\n",
       "       [-0.04215506,  0.03989936,  0.01973895],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.03319181, -0.02486175, -0.03930579],\n",
       "       [ 0.02817862, -0.02355758,  0.02211039],\n",
       "       [-0.02172632,  0.00056459,  0.01340276],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.04965601, -0.00995258, -0.04661613],\n",
       "       [ 0.02817862, -0.02355758,  0.02211039],\n",
       "       [ 0.02973333,  0.00432855, -0.00251607],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [-0.02268566, -0.02677369,  0.04340892],\n",
       "       [ 0.02817862, -0.02355758,  0.02211039],\n",
       "       [ 0.03118895, -0.02061788, -0.0336071 ],\n",
       "       [ 0.00147326,  0.04134904, -0.00857757],\n",
       "       [ 0.02338589, -0.02350946,  0.04454089],\n",
       "       [ 0.02708576, -0.01448844,  0.03393655],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.03283953,  0.03530599, -0.03119474],\n",
       "       [ 0.03748092, -0.03771096,  0.04293822],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.0345609 ,  0.02477014,  0.02694254],\n",
       "       [-0.01751279, -0.0466769 ,  0.01438934],\n",
       "       [-0.03384425,  0.01651653,  0.03690077],\n",
       "       [ 0.03315941,  0.04482063,  0.04294814],\n",
       "       [ 0.03748092, -0.03771096,  0.04293822],\n",
       "       [-0.04084514,  0.03854592,  0.01677524],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [-0.04183261, -0.03248701,  0.02310926],\n",
       "       [ 0.02817862, -0.02355758,  0.02211039],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [ 0.02817862, -0.02355758,  0.02211039],\n",
       "       [ 0.02973333,  0.00432855, -0.00251607],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.03874655, -0.0020466 , -0.02378233],\n",
       "       [-0.04183261, -0.03248701,  0.02310926],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.00097542, -0.00299772, -0.00754408],\n",
       "       [-0.00471734, -0.04747161,  0.02368059],\n",
       "       [-0.00976199, -0.00605768, -0.03696854],\n",
       "       [-0.02935201,  0.02717162, -0.03102981],\n",
       "       [ 0.00270077, -0.04598354, -0.00501931],\n",
       "       [-0.04615469,  0.0352147 ,  0.03563979],\n",
       "       [ 0.03359706,  0.03035219, -0.02061803],\n",
       "       [ 0.03798262,  0.01415141, -0.03752277],\n",
       "       [-0.02102023, -0.01957666, -0.02398382],\n",
       "       [ 0.03056136, -0.03746762, -0.00198074],\n",
       "       [-0.02310274,  0.00490242, -0.02524453],\n",
       "       [-0.01209395,  0.0232675 ,  0.04716427],\n",
       "       [ 0.04415346, -0.00783243, -0.00171115],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [-0.03462116, -0.04399797, -0.04942012],\n",
       "       [-0.01751279, -0.0466769 ,  0.01438934],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.03315941,  0.04482063,  0.04294814],\n",
       "       [-0.03283953,  0.03530599, -0.03119474],\n",
       "       [ 0.03748092, -0.03771096,  0.04293822],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.0345609 ,  0.02477014,  0.02694254],\n",
       "       [-0.04084514,  0.03854592,  0.01677524],\n",
       "       [-0.01751279, -0.0466769 ,  0.01438934],\n",
       "       [ 0.01166736,  0.02015115,  0.0003668 ],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [ 0.02932182, -0.01262702, -0.01792549],\n",
       "       [-0.03285612,  0.02369666,  0.04971344],\n",
       "       [ 0.03643907, -0.00522773, -0.04958069],\n",
       "       [ 0.02338589, -0.02350946,  0.04454089],\n",
       "       [-0.03283953,  0.03530599, -0.03119474],\n",
       "       [ 0.03748092, -0.03771096,  0.04293822],\n",
       "       [ 0.00127006,  0.02444062,  0.03954462],\n",
       "       [-0.0345609 ,  0.02477014,  0.02694254],\n",
       "       [-0.04523039,  0.03359672,  0.04709405],\n",
       "       [-0.02468344,  0.0092126 ,  0.0348318 ],\n",
       "       [ 0.00097542, -0.00299772, -0.00754408]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = keras.layers.Embedding(\n",
    "    tv_int.vocabulary_size(),\n",
    "    3, # longueur des vecteurs\n",
    "    mask_zero=True # important si padding\n",
    ")\n",
    "embeddings(one_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c95782-c1c3-4f1d-92fa-e9a86b3eb7b1",
   "metadata": {},
   "source": [
    "# Un modèle avec une couche d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1ef4f5-ccd0-4694-861a-e18598b232ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(tv, emb_dim, nb_classes):\n",
    "    inputs = keras.layers.Input(shape=(100,))\n",
    "    embeddings = keras.layers.Embedding(\n",
    "        tv.vocabulary_size(),\n",
    "        emb_dim,\n",
    "        mask_zero=True,\n",
    "        name=\"emb\"\n",
    "    )(inputs)\n",
    "    embeddings = keras.layers.Dropout(rate=0.2)(embeddings)\n",
    "    pooling = keras.layers.GlobalMaxPooling1D()(embeddings)\n",
    "    classif = keras.layers.Dense(nb_classes, activation=\"softmax\", use_bias=True)(pooling)\n",
    "    model = keras.Model(inputs=inputs, outputs=classif)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e749c5-a78d-48e7-aa21-22f8797c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(tv_int, 300, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e13a2b0-c0fb-4acb-a87f-5fae3e9c95a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " emb (Embedding)             (None, 100, 300)          900000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 300)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 300)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 2107      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 902107 (3.44 MB)\n",
      "Trainable params: 902107 (3.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b4d97c-fa5a-43c9-9d4f-ffd148054353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_int(x,y):\n",
    "    return tv_int(x),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "676b8bd4-6160-4b6a-abec-4bbd1e4b338b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(ds_train.map(preproc_int),  validation_data=ds_valid.map(preproc_int), epochs=10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809aa427-630f-4cf3-97e9-cdd85cd31dd1",
   "metadata": {},
   "source": [
    "# visualisation\n",
    "\n",
    "création de fichiers tsv prêts à être chargés sur https://projector.tensorflow.org/ \n",
    "(cf le code dans utils_TP5.py pour l'extraction des poids qui correspondent aux vecteurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7da5f852-90d9-432e-9bec-bd51db5dac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_TP5 import write_vectors_proj_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ad0ed69-8eed-4319-82c7-0f740f307de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vectors_proj_format(model, tv_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a7da6-fca5-479a-b085-4b669b1ff17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf551cdc-d12e-45cb-abb3-7c3714a35543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397eddf3-5ef9-4f52-9fd2-57efe1d67c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ec7234-c973-4842-8392-1f4f736eefa0",
   "metadata": {},
   "source": [
    "# Debut TP 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3a583a-3c1f-4aac-90f0-bf31675d32c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 18:57:44.018636: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-25 18:57:44.338644: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-25 18:57:44.338715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-25 18:57:44.396377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-25 18:57:44.513214: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-25 18:57:44.515044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 18:57:45.689917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TextLineDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TP 7 \n",
    "# Corpus avec étiquette morphosyntaxique\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import TextLineDataset\n",
    "\n",
    "ds=TextLineDataset(\"aij-wikiner-fr-wp2\")\n",
    "\n",
    "ds  # entire dataset object  with token|POS tag | BIO tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2668f9-7234-4473-98ae-bef492eb8b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b\"Il|PRO:PER|O assure|VER:pres|O \\xc3\\xa0|VER:pper|O la|DET:ART|O suite|NOM|O de|PRP|I-PER Saussure|NAM|I-PER le|DET:ART|O cours|NOM|O de|PRP|O grammaire|NOM|O compar\\xc3\\xa9e|ADJ|O ,|PUN|O qu'|PRO:REL|O il|PRO:PER|O compl\\xc3\\xa8te|VER:subp|O \\xc3\\xa0|VER:pper|O partir|VER:infi|O de|PRP|O 1894|NUM|O par|PRP|O une|DET:ART|O conf\\xc3\\xa9rence|NOM|O sur|PRP|O l'|DET:ART|O iranien|ADJ|O .|SENT|O\">"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_ds = ds.skip(1).take(1).get_single_element()\n",
    "tst_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489db6a6-10be-4d59-8fcd-e8d84c5e4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_split(tensor):\n",
    "    # return tf.strings.split(tensor, sep=\"|\", maxsplit=-1, name=None)\n",
    "    t = tf.strings.split(tensor)\n",
    "    # return t\n",
    "    X,y = tf.strings.split(t, sep=\"|\", maxsplit=-1, name=None)[:, :1], tf.strings.split(t, sep=\"|\", maxsplit=-1, name=None)[:, 1:2]\n",
    "    \n",
    "    return X, y\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9973c8-7a22-4d98-96ad-1dda9637c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y = ds.map(tensor_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3380b4b-97ea-4786-a1ee-7b2e5565229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction du texte\n",
    "X_data = X_y.map(lambda x, y: x) # data \n",
    "y_labels = X_y.map(lambda x, y: y) # lables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d19da2-a766-4589-b235-72420b27e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (text): <tf.RaggedTensor []>\n",
      "X (text): <tf.RaggedTensor [[b'Il'],\n",
      " [b'assure'],\n",
      " [b'\\xc3\\xa0'],\n",
      " [b'la'],\n",
      " [b'suite'],\n",
      " [b'de'],\n",
      " [b'Saussure'],\n",
      " [b'le'],\n",
      " [b'cours'],\n",
      " [b'de'],\n",
      " [b'grammaire'],\n",
      " [b'compar\\xc3\\xa9e'],\n",
      " [b','],\n",
      " [b\"qu'\"],\n",
      " [b'il'],\n",
      " [b'compl\\xc3\\xa8te'],\n",
      " [b'\\xc3\\xa0'],\n",
      " [b'partir'],\n",
      " [b'de'],\n",
      " [b'1894'],\n",
      " [b'par'],\n",
      " [b'une'],\n",
      " [b'conf\\xc3\\xa9rence'],\n",
      " [b'sur'],\n",
      " [b\"l'\"],\n",
      " [b'iranien'],\n",
      " [b'.']]>\n",
      "X (text): <tf.RaggedTensor [[b'En'],\n",
      " [b'1905'],\n",
      " [b','],\n",
      " [b'il'],\n",
      " [b'occupe'],\n",
      " [b'la'],\n",
      " [b'chaire'],\n",
      " [b'de'],\n",
      " [b'grammaire'],\n",
      " [b'compar\\xc3\\xa9e'],\n",
      " [b'au'],\n",
      " [b'Coll\\xc3\\xa8ge'],\n",
      " [b'de'],\n",
      " [b'France'],\n",
      " [b','],\n",
      " [b'o\\xc3\\xb9'],\n",
      " [b'il'],\n",
      " [b'consacre'],\n",
      " [b'ses'],\n",
      " [b'cours'],\n",
      " [b'\\xc3\\xa0'],\n",
      " [b\"l'\"],\n",
      " [b'histoire'],\n",
      " [b'et'],\n",
      " [b'\\xc3\\xa0'],\n",
      " [b'la'],\n",
      " [b'structure'],\n",
      " [b'des'],\n",
      " [b'langues'],\n",
      " [b'indo-europ\\xc3\\xa9ennes'],\n",
      " [b'.']]>\n",
      "X (text): <tf.RaggedTensor [[b'Il'],\n",
      " [b'a'],\n",
      " [b'form\\xc3\\xa9'],\n",
      " [b'toute'],\n",
      " [b'une'],\n",
      " [b'g\\xc3\\xa9n\\xc3\\xa9ration'],\n",
      " [b'de'],\n",
      " [b'linguistes'],\n",
      " [b'fran\\xc3\\xa7ais'],\n",
      " [b','],\n",
      " [b'parmi'],\n",
      " [b'lesquels'],\n",
      " [b'Emile'],\n",
      " [b'Benveniste'],\n",
      " [b','],\n",
      " [b'Marcel'],\n",
      " [b'Cohen'],\n",
      " [b','],\n",
      " [b'Georges'],\n",
      " [b'Dum\\xc3\\xa9zil'],\n",
      " [b','],\n",
      " [b'Andr\\xc3\\xa9'],\n",
      " [b'Martinet'],\n",
      " [b','],\n",
      " [b'Aur\\xc3\\xa9lien'],\n",
      " [b'Sauvageot'],\n",
      " [b','],\n",
      " [b'Lucien'],\n",
      " [b'Tesni\\xc3\\xa8re'],\n",
      " [b','],\n",
      " [b'Joseph'],\n",
      " [b'Vendryes'],\n",
      " [b'.']]>\n",
      "X (text): <tf.RaggedTensor [[b'Il'],\n",
      " [b'devait'],\n",
      " [b'diriger'],\n",
      " [b'la'],\n",
      " [b'th\\xc3\\xa8se'],\n",
      " [b'de'],\n",
      " [b'Jean'],\n",
      " [b'Paulhan'],\n",
      " [b'sur'],\n",
      " [b'la'],\n",
      " [b's\\xc3\\xa9mantique'],\n",
      " [b'du'],\n",
      " [b'proverbe'],\n",
      " [b'et'],\n",
      " [b\"c'\"],\n",
      " [b'est'],\n",
      " [b'lui'],\n",
      " [b'qui'],\n",
      " [b'd\\xc3\\xa9couvrit'],\n",
      " [b'Gustave'],\n",
      " [b'Guillaume'],\n",
      " [b'.']]>\n"
     ]
    }
   ],
   "source": [
    "for X in X_data.take(5):  # first 5 text elements\n",
    "    print(\"X (text):\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d088fc8f-d626-4f45-b7ae-5161a49de7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels (text): <tf.RaggedTensor []>\n",
      "Labels (text): <tf.RaggedTensor [[b'PRO:PER'],\n",
      " [b'VER:pres'],\n",
      " [b'VER:pper'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP'],\n",
      " [b'NAM'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP'],\n",
      " [b'NOM'],\n",
      " [b'ADJ'],\n",
      " [b'PUN'],\n",
      " [b'PRO:REL'],\n",
      " [b'PRO:PER'],\n",
      " [b'VER:subp'],\n",
      " [b'VER:pper'],\n",
      " [b'VER:infi'],\n",
      " [b'PRP'],\n",
      " [b'NUM'],\n",
      " [b'PRP'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP'],\n",
      " [b'DET:ART'],\n",
      " [b'ADJ'],\n",
      " [b'SENT']]>\n",
      "Labels (text): <tf.RaggedTensor [[b'PRP'],\n",
      " [b'NUM'],\n",
      " [b'PUN'],\n",
      " [b'PRO:PER'],\n",
      " [b'VER:pres'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP'],\n",
      " [b'NOM'],\n",
      " [b'ADJ'],\n",
      " [b'PRP:det'],\n",
      " [b'NAM'],\n",
      " [b'PRP'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'VER:pper'],\n",
      " [b'PRO:PER'],\n",
      " [b'VER:pres'],\n",
      " [b'DET:POS'],\n",
      " [b'NOM'],\n",
      " [b'VER:pper'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'KON'],\n",
      " [b'NOM'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP:det'],\n",
      " [b'NOM'],\n",
      " [b'ADJ'],\n",
      " [b'SENT']]>\n",
      "Labels (text): <tf.RaggedTensor [[b'PRO:PER'],\n",
      " [b'VER:pres'],\n",
      " [b'VER:pper'],\n",
      " [b'PRO:IND'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP'],\n",
      " [b'NOM'],\n",
      " [b'ADJ'],\n",
      " [b'PUN'],\n",
      " [b'PRP'],\n",
      " [b'PRO:REL'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PUN'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'SENT']]>\n",
      "Labels (text): <tf.RaggedTensor [[b'PRO:PER'],\n",
      " [b'VER:impf'],\n",
      " [b'VER:infi'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'PRP'],\n",
      " [b'DET:ART'],\n",
      " [b'NOM'],\n",
      " [b'PRP:det'],\n",
      " [b'NOM'],\n",
      " [b'KON'],\n",
      " [b'PRO:DEM'],\n",
      " [b'VER:pres'],\n",
      " [b'PRO:PER'],\n",
      " [b'PRO:REL'],\n",
      " [b'VER:simp'],\n",
      " [b'NAM'],\n",
      " [b'NAM'],\n",
      " [b'SENT']]>\n"
     ]
    }
   ],
   "source": [
    "for y in y_labels.take(5):  #  first 5 label elements\n",
    "    print(\"Labels (text):\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4b631-5c2a-48c1-9735-145d6882a0c4",
   "metadata": {},
   "source": [
    "### A continuer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc74c0e-4932-4144-8bf7-a7c16389a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tv = solution.get_text_vectorizer_from_config(solution.ExpeConfig(\"whitespace\",None,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4bf687b-008b-4645-be8d-e4765af71d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preproc(x,y):\n",
    "#     return tv(x),y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0e26891-85f2-4576-9374-0a16846d600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = utils.PerceptronModelSparseCategorical(tv, list(range(7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f31027d2-8ee4-4caa-ada7-9df4e0dca3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_6005/711123526.py\", line 2, in preproc  *\n        return tv(x),y\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 588, in _preprocess\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'text_vectorization' (type TextVectorization).\n    \n    When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, None) with rank=2\n    \n    Call arguments received by layer 'text_vectorization' (type TextVectorization):\n      • inputs=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_y\u001b[38;5;241m.\u001b[39mmap(preproc), validation_data\u001b[38;5;241m=\u001b[39mX_y\u001b[38;5;241m.\u001b[39mmap(preproc), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_op\u001b[38;5;241m.\u001b[39m_map_v2(\n\u001b[1;32m   2281\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2282\u001b[0m     map_func,\n\u001b[1;32m   2283\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m   2284\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m   2285\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[38;5;241m=\u001b[39minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[38;5;241m=\u001b[39muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m fn_factory()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwargs, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m    696\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    697\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m wrapper_helper(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, ag_ctx)(\u001b[38;5;241m*\u001b[39mnested_args)\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9r72l_8k.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preproc\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tv), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(y))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py:588\u001b[0m, in \u001b[0;36mTextVectorization._preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `TextVectorization` to tokenize strings, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe input rank must be 1 or the last shape dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be 1. Received: inputs.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith rank=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m         )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    595\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_6005/711123526.py\", line 2, in preproc  *\n        return tv(x),y\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 588, in _preprocess\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'text_vectorization' (type TextVectorization).\n    \n    When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, None) with rank=2\n    \n    Call arguments received by layer 'text_vectorization' (type TextVectorization):\n      • inputs=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03f2901b-4ba5-470d-b9bf-4d5372a6ff2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/base_preprocessing_layer.py\", line 123, in adapt_step  *\n        self.update_state(data)\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 476, in update_state  **\n        self._lookup_layer.update_state(self._preprocess(data))\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 588, in _preprocess\n        raise ValueError(\n\n    ValueError: When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, None) with rank=2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tv\u001b[38;5;241m.\u001b[39madapt(X_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py:473\u001b[0m, in \u001b[0;36mTextVectorization.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madapt\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    424\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes a vocabulary of string terms from tokens in a dataset.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m    Calling `adapt()` on a `TextVectorization` layer is an alternative to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m          argument is not supported with array inputs.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39madapt(data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, steps\u001b[38;5;241m=\u001b[39msteps)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/base_preprocessing_layer.py:258\u001b[0m, in \u001b[0;36mPreprocessingLayer.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m--> 258\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapt_function(iterator)\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m    260\u001b[0m             context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileslilfpui.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__adapt_step\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_adapt_maybe_build, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py:476\u001b[0m, in \u001b[0;36mTextVectorization.update_state\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lookup_layer\u001b[38;5;241m.\u001b[39mupdate_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess(data))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py:588\u001b[0m, in \u001b[0;36mTextVectorization._preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `TextVectorization` to tokenize strings, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe input rank must be 1 or the last shape dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be 1. Received: inputs.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith rank=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m         )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    595\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/base_preprocessing_layer.py\", line 123, in adapt_step  *\n        self.update_state(data)\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 476, in update_state  **\n        self._lookup_layer.update_state(self._preprocess(data))\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 588, in _preprocess\n        raise ValueError(\n\n    ValueError: When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, None) with rank=2\n"
     ]
    }
   ],
   "source": [
    "tv.adapt(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "469e68f5-dabd-4eee-ad3e-228a0443c060",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_6005/3658695583.py\", line 11, in None  *\n        lambda x,y: (tv(x),y)\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 588, in _preprocess\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'text_vectorization' (type TextVectorization).\n    \n    When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, None) with rank=2\n    \n    Call arguments received by layer 'text_vectorization' (type TextVectorization):\n      • inputs=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#copy code\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# tv.adapt(X_text)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ds_train.map(lambda x,y: (tv(x),y)).take(1).get_single_element()\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m X_y\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x,y: (tv(x),y))\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mget_single_element()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_op\u001b[38;5;241m.\u001b[39m_map_v2(\n\u001b[1;32m   2281\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2282\u001b[0m     map_func,\n\u001b[1;32m   2283\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m   2284\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m   2285\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[38;5;241m=\u001b[39minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[38;5;241m=\u001b[39muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m fn_factory()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwargs, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m    696\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    697\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m wrapper_helper(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, ag_ctx)(\u001b[38;5;241m*\u001b[39mnested_args)\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filexxe60rzz.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: (ag__\u001b[38;5;241m.\u001b[39mconverted_call(tv, (x,), \u001b[38;5;28;01mNone\u001b[39;00m, lscope), y), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/core/function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_\u001b[39m\u001b[38;5;124m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m thunk(scope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filexxe60rzz.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: (ag__\u001b[38;5;241m.\u001b[39mconverted_call(tv, (x,), \u001b[38;5;28;01mNone\u001b[39;00m, lscope), y), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py:588\u001b[0m, in \u001b[0;36mTextVectorization._preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `TextVectorization` to tokenize strings, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe input rank must be 1 or the last shape dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be 1. Received: inputs.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith rank=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m         )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    595\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_6005/3658695583.py\", line 11, in None  *\n        lambda x,y: (tv(x),y)\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/shamglam/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/preprocessing/text_vectorization.py\", line 588, in _preprocess\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'text_vectorization' (type TextVectorization).\n    \n    When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, None) with rank=2\n    \n    Call arguments received by layer 'text_vectorization' (type TextVectorization):\n      • inputs=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#copy code\n",
    "\n",
    "\n",
    "# tv = solution.get_text_vectorizer_from_config(solution.ExpeConfig(\"whitespace\",None,1000))\n",
    "\n",
    "\n",
    "\n",
    "# tv.adapt(X_text)\n",
    "# ds_train.map(lambda x,y: (tv(x),y)).take(1).get_single_element()\n",
    "\n",
    "# X_y.map(lambda x,y: (tv(x),y)).take(1).get_single_element()\n",
    "\n",
    "# model = utils.PerceptronModelSparseCategorical(tv, list(range(7)))\n",
    "\n",
    "# def preproc(x,y):\n",
    "#     return tv(x),y(\n",
    "\n",
    "\n",
    "# model.fit(ds_train.map(preproc), validation_data=ds_valid.map(preproc), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43e1e7-3b40-49c2-ba9d-7de9113aeb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "617bc6a8-435f-45cc-bfcb-8da925175c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TextVectorization.vocabulary_size of <keras.src.layers.preprocessing.text_vectorization.TextVectorization object at 0x7275df0bd950>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tv.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f1828-849f-4c30-8399-7c754d165398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
